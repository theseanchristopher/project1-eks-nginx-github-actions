# ==========================================================================================
# GitHub Actions Workflow – Branch Strategy Overview
#
# This repository supports two parallel deployment models for the same application:
#
#   1. **main branch**  → Traditional push-based CI/CD (Project 1)
#      -----------------------------------------------------------
#      - Builds and pushes the application image to ECR.
#      - Deploys directly to the EKS cluster using kubectl.
#      - Represents the classic CI/CD model from Project 1.
#      - No interaction with any GitOps repository.
#
#   2. **project4-gitops branch**  → GitOps-based CI/CD (Project 4 Integration)
#      ------------------------------------------------------------------------
#      - Builds and pushes the application image to ECR (same as main).
#      - After pushing the image, updates the Project 4 GitOps repo
#            (theseanchristopher/project4-helm-argo-gitops)
#        by modifying the Helm dev values file:
#            charts/app/values-dev.yaml  (image.tag)
#      - Argo CD automatically detects this Git commit, syncs the change,
#        and deploys the new image to the EKS cluster using pull-based CD.
#      - Job 2 (direct kubectl deployment) is disabled for this branch via
#        the `if: github.ref == 'refs/heads/main'` condition.
#
# NOTE:
# - This workflow file is intentionally BRANCH-SCOPED.
# - The copy of ci-cd.yaml on project4-gitops should only target Project 4.
# - The Project 3 GitOps integration remains on the project3-gitops branch.
#
# ==========================================================================================

name: CI/CD to EKS

on:
  push:
    # Run this pipeline when changes are pushed to the project4-gitops branch
    branches: [ project4-gitops ]
    # Limit triggers to application code, Kubernetes manifests, or workflow changes
    paths:
      - "app/**"
      - "k8s/**"
      - ".github/workflows/**"

jobs:
  # ------------------------------
  # Job 1: Build and push Docker image to ECR
  # ------------------------------
  build-and-push:
    name: Build and Push to ECR
    runs-on: ubuntu-latest

    steps:
      - name: DEBUG – workflow version 2025-12-31-project4
        run: |
          echo "DEBUG: running Project 4 GitOps workflow on project4-gitops branch"

      # Check out the repository contents so the runner has access to app/ and k8s/
      - name: Checkout code
        uses: actions/checkout@v4

      # Configure AWS credentials for this job using GitHub Actions secrets.
      # These credentials are used by both the AWS CLI and Docker (via ECR auth).
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Authenticate the local Docker client to Amazon ECR so we can push images.
      - name: Login to Amazon ECR
        id: login-ecr
        run: |
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} \
            | docker login \
              --username AWS \
              --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com

      # Build the Docker image from app/, tag it with the commit SHA for traceability,
      # and push it to the ECR repository configured for this project.
      - name: Build, tag, and push image
        env:
          ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
        run: |
          # Use the Git commit SHA as an immutable image tag
          IMAGE_TAG=${GITHUB_SHA}

          # Build the container image from the Dockerfile in app/
          docker build -t $ECR_REPOSITORY:latest ./app

          # Retag the image with the full ECR registry/repository path + SHA tag
          docker tag $ECR_REPOSITORY:latest $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

          # Push the SHA-tagged image to ECR
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

          # Optionally expose the full image reference as a step output (not consumed yet)
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      # ---------------------------------------------
      # Update Project 4 GitOps repo with the new image tag.
      #
      # This step connects Project 1's CI pipeline to Project 4's GitOps configuration.
      # After building and pushing the application image to ECR, we update the Helm
      # dev values file in the Project 4 GitOps repo:
      #
      #   charts/app/values-dev.yaml  (image.tag)
      #
      # Argo CD automatically detects this Git commit and syncs the new image version
      # into the EKS cluster (pull-based CD).
      #
      # IMPORTANT:
      # - Uses a PAT stored in PROJECT4_REPO_PAT (never hard-coded).
      # - Updates only the Project 4 repo—NO changes occur to Project 1 manifests.
      # - This enables fully automated CI → GitOps → Argo CD → EKS deployment for dev.
      # ---------------------------------------------

      # Install yq (YAML-safe editor)
      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq

      - name: Checkout Project 4 GitOps repo
        uses: actions/checkout@v4
        with:
          repository: theseanchristopher/project4-helm-argo-gitops
          ref: project4-gitops
          token: ${{ secrets.PROJECT4_REPO_PAT }}
          path: project4-gitops

      - name: Update Project 4 dev image tag
        working-directory: project4-gitops
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Current charts/app/values-dev.yaml:"
          cat charts/app/values-dev.yaml

          # Set image.tag to the current IMAGE_TAG
          yq -i '.image.tag = env(IMAGE_TAG)' charts/app/values-dev.yaml

          echo "Updated charts/app/values-dev.yaml:"
          cat charts/app/values-dev.yaml

      - name: Commit and push changes to Project 4 GitOps repo
        working-directory: project4-gitops
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

          # Only commit if there are changes
          if ! git diff --quiet; then
            git add charts/app/values-dev.yaml
            git commit -m "Update Project 4 dev image tag to ${IMAGE_TAG}"
            git push origin project4-gitops
          else
            echo "No changes to commit."
          fi

  # ------------------------------
  # Job 2: Deploy to EKS and run smoke test
  # ------------------------------
  deploy:
    # Only execute on the 'main' branch.
    # NOTE: Since this workflow is triggered only on project4-gitops,
    #       this job is effectively disabled here and remains as
    #       documentation for the classic main-branch CI/CD path.
    if: github.ref == 'refs/heads/main'

    name: Deploy to EKS
    runs-on: ubuntu-latest

    # Ensure the deployment only runs if the image build/push was successful
    needs: build-and-push

    steps:
      # Check out the repo again on this fresh runner instance
      - name: Checkout code
        uses: actions/checkout@v4

      # Configure AWS credentials for talking to EKS and other AWS APIs
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Install kubectl so we can apply manifests and query Kubernetes objects
      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "latest"

      # Populate kubeconfig with the EKS cluster endpoint and credentials.
      # This allows kubectl to authenticate to the correct EKS cluster.
      - name: Update kubeconfig for EKS cluster
        run: |
          aws eks update-kubeconfig \
            --name "${{ secrets.EKS_CLUSTER_NAME }}" \
            --region "${{ secrets.AWS_REGION }}"

      # Update the Kubernetes Deployment manifest to use the newly built image.
      # We replace a placeholder in deployment.yaml with the SHA-tagged image URI.
      - name: Set image in deployment manifest
        env:
          ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
        run: |
          IMAGE_TAG=${GITHUB_SHA}

          # Replace IMAGE_PLACEHOLDER in k8s/deployment.yaml with the full image reference
          sed -i "s#IMAGE_PLACEHOLDER#$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG#g" k8s/deployment.yaml

      # Apply all Kubernetes manifests to the target namespace and wait for the rollout.
      # This ensures the deployment is healthy before we run the smoke test.
      - name: Apply Kubernetes manifests and wait for rollout to finish
        env:
          K8S_NAMESPACE: ${{ secrets.K8S_NAMESPACE }}
        run: |
          # Ensure target namespace exists or create.
          kubectl get namespace "$K8S_NAMESPACE" || kubectl create namespace "$K8S_NAMESPACE"

          # Apply all manifests in the k8s/ directory to the specified namespace
          kubectl apply -n $K8S_NAMESPACE -f k8s/

          # Wait for the nginx deployment to finish rolling out
          kubectl rollout status deployment/nginx-deployment -n $K8S_NAMESPACE --timeout=120s

      # Perform a simple HTTPS smoke test against the Ingress host.
      # This validates that the app is reachable over HTTPS and serving the expected content.
      - name: Smoke test service via Ingress
        env:
          K8S_NAMESPACE: ${{ secrets.K8S_NAMESPACE }}
          EXPECTED_CONTENT: "Project 1 - Nginx on EKS via GitHub Actions"
        run: |
          set +e  # Do not exit immediately on errors; we handle failures explicitly.

          echo "Namespace: $K8S_NAMESPACE"
          echo "Expected content: $EXPECTED_CONTENT"

          # Retrieve the host configured on the Ingress (e.g., project1.seanxtopher.com)
          LB_HOST=$(kubectl get ingress nginx-ingress -n "$K8S_NAMESPACE" -o jsonpath='{.spec.rules[0].host}')
          echo "LB_HOST=$LB_HOST"
          echo "Waiting for HTTPS endpoint to become ready..."

          # Retry loop to allow DNS/ALB propagation and pod readiness
          for i in {1..20}; do
            # -s: silent, -S: show error, --fail: non-zero on HTTP errors
            RESPONSE=$(curl -sS --fail https://$LB_HOST || true)
            echo "Attempt $i: $RESPONSE"

            # Look for a known string from the custom landing page to confirm success
            if echo "$RESPONSE" | grep -q "$EXPECTED_CONTENT"; then
              echo "App is responding correctly over HTTPS!"
              exit 0
            fi

            sleep 5
          done

          echo "App did not return the expected content after multiple attempts."
          exit 1
